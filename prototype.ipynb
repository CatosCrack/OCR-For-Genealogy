{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a90470b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "import csv\n",
    "import utils\n",
    "\n",
    "class ner_model:\n",
    "    \"\"\"\n",
    "    This class is used to load and configure a custom Named Entity Recognition (NER) model\n",
    "    using the spaCy library. It sets up the NER pipeline with pre-trained models and custom\n",
    "    entity patterns for improved accuracy in entity extraction.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        # Load pre-trained and custom NER models for extraction\n",
    "        self._nlp_es = spacy.load(\"es_core_news_lg\")\n",
    "        self._nlp_custom = spacy.load(\"ner_model/model/model-best\")\n",
    "\n",
    "        # Create a matcher to improve accuracy \n",
    "        self._matcher = Matcher(self._nlp_es.vocab)\n",
    "\n",
    "        # Load list of names\n",
    "        names = []\n",
    "        last_names = []\n",
    "\n",
    "        with open('ner_model/data/processed/first_names_processed.csv', 'r', newline=\"\") as file:\n",
    "            reader = csv.reader(file, delimiter=\",\")\n",
    "            for row in reader:\n",
    "                names.append(row[0])\n",
    "\n",
    "        with open('ner_model/data/processed/last_names_processed.csv', 'r', newline='') as file:\n",
    "            reader = csv.reader(file, delimiter=\",\")\n",
    "            for row in reader:\n",
    "                last_names.append(row[0])\n",
    "\n",
    "        # Add names and last names to entity ruler\n",
    "        ruler = self._nlp_custom.add_pipe(\"entity_ruler\", after=\"ner\", config={\"overwrite_ents\":True})\n",
    "\n",
    "        # Create patterns\n",
    "        patterns = []\n",
    "        match_patterns = []\n",
    "        for name in names:\n",
    "            patterns.append({\n",
    "                \"label\":\"FIRST_NAME\",\n",
    "                \"pattern\": [{\"LOWER\":name.lower()}]\n",
    "            })\n",
    "            match_patterns.append([{\"LOWER\":name.lower()}])\n",
    "    \n",
    "        # Add patterns to matcher\n",
    "        self._matcher.add(\"FIRST_NAME\", match_patterns)\n",
    "\n",
    "        match_patterns = []\n",
    "        for name in last_names:\n",
    "            patterns.append({\n",
    "                \"label\":\"LAST_NAME\",\n",
    "                \"pattern\": [{\"LOWER\":name.lower()}]\n",
    "            })\n",
    "            match_patterns.append([{\"LOWER\":name.lower()}])\n",
    "\n",
    "        # Add patterns to pipeline and matcher\n",
    "        self._matcher.add(\"LAST_NAME\", match_patterns)\n",
    "        ruler.add_patterns(patterns)\n",
    "\n",
    "    def extract_names(self, text_blocks, original_text, token_map):\n",
    "        ## TODO: Need to find a way to be a bit more flexible with the choice\n",
    "\n",
    "        results = []\n",
    "\n",
    "        for block in text_blocks:\n",
    "            # Extract names\n",
    "            print(\"---------- New Block ----------\")\n",
    "            doc = self._nlp_es(block)\n",
    "            for ent in doc.ents:\n",
    "                if ent.label_ == \"PER\":\n",
    "                    print(\"## Name found by default model: \", ent, ent.label_)\n",
    "            \n",
    "                    # Get bounding boxes for the entire entity and append to database register\n",
    "                    bounds = utils.get_bounding_box(ent.text, original_text, token_map)\n",
    "\n",
    "                    # Split entity to clasiffy in first name and last name\n",
    "                    tokens = ent.text.split(\" \")\n",
    "\n",
    "                    # Gather first names and last names\n",
    "                    first_names = []\n",
    "                    last_names = []\n",
    "\n",
    "                    # Identify names in the entity\n",
    "                    for token in tokens:\n",
    "                        name = self._nlp_custom(utils.remove_accent(token))\n",
    "                        matches = self._matcher(name)\n",
    "                        for name_ent in name.ents:\n",
    "                            if len(matches) > 0 and name_ent.label_ == self._nlp_es.vocab[matches[0][0]].text:\n",
    "                                # Add to corresponding name list\n",
    "                                if name_ent.label_ == \"FIRST_NAME\":\n",
    "                                    first_names.append(name_ent.text)\n",
    "                                elif name_ent.label_ == \"LAST_NAME\":\n",
    "                                    last_names.append(name_ent.text)\n",
    "                        \n",
    "                                # Print recognition data\n",
    "                                print(\"     -- MATCHES MATCHER. Custom model results: \", \n",
    "                                    name_ent, \n",
    "                                    name_ent.label_, \n",
    "                                    \"/ Matcher results: \", \n",
    "                                    name[matches[0][1]:matches[0][2]],\n",
    "                                    self._nlp_es.vocab[matches[0][0]].text)\n",
    "                        \n",
    "                            elif len(matches) == 0:\n",
    "                                continue\n",
    "\n",
    "                            else:\n",
    "                                print(\"     -- DISCREPANCY WITH MATCHER. Custom model results: \", \n",
    "                                    name_ent, name_ent.label_, \n",
    "                                    name[matches[0][1]:matches[0][2]], \n",
    "                                    self._nlp_es.vocab[matches[0][0]].text)\n",
    "            \n",
    "                    # Process names separated by a space\n",
    "                    for i in range(len(tokens)):\n",
    "                        if i+1 < len(tokens):\n",
    "                            combined = self._nlp_custom(tokens[i]+tokens[i+1])\n",
    "                            match = self._matcher(combined)\n",
    "                            if match and combined.ents[0].label_ == self._nlp_es.vocab[match[0][0]].text:\n",
    "                                # Add to corresponding name list\n",
    "                                if combined.ents[0].label_ == \"FIRST_NAME\":\n",
    "                                    first_names.append(combined.ents[0].text)\n",
    "                                elif combined.ents[0].label_ == \"LAST_NAME\":\n",
    "                                    last_names.append(combined.ents[0].text)\n",
    "            \n",
    "                    # Add first and last names to name list\n",
    "                    # If no first names are found, set to None\n",
    "                    if first_names:\n",
    "                        print(\"#### Joining first names...\")\n",
    "                        first_names = \" \".join(first_names)\n",
    "                        print(\"     -- First Names: \", first_names)\n",
    "                    else:\n",
    "                        print(\"#### No names found. Setting to none: \", first_names)\n",
    "                        first_names = None\n",
    "\n",
    "                    # If no last names are found, set to None\n",
    "                    if last_names:\n",
    "                        print(\"#### Joining last names...\")\n",
    "                        last_names = \" \".join(last_names)\n",
    "                        print(\"     -- Last Names: \", last_names)\n",
    "                    else:\n",
    "                        print(\"#### No names found. Setting to none: \", last_names)\n",
    "                        last_names = None\n",
    "                    \n",
    "                    # Append entity to results\n",
    "                    results.append({\n",
    "                        \"first_name\": first_names,\n",
    "                        \"last_name\": last_names,\n",
    "                        \"bounding_box\": bounds\n",
    "                    })\n",
    "\n",
    "        # Return the extracted names and their bounding boxes\n",
    "        return results\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4555602f-6a8c-495f-b7fd-caf1ecbf2469",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "App initialized\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import documentai_v1 as documentai\n",
    "from google.oauth2 import service_account\n",
    "from database import Database\n",
    "import re\n",
    "import utils\n",
    "\n",
    "db = Database()\n",
    "\n",
    "# Base processor data\n",
    "project_id = \"genealogy-ocr-index\"\n",
    "location = \"us\"\n",
    "processor_id = \"4cb2ae40b145c48\"\n",
    "\n",
    "class ocr_engine:\n",
    "    \"\"\"\n",
    "        This class is used to load a Google Document AI processor and perform OCR on images stored in a Google Cloud Storage bucket.\n",
    "        It extracts text from the images, identifies names using a custom NER model, and stores the results in a Firestore database.\n",
    "    \"\"\"\n",
    "    def __init__(self) -> None:\n",
    "\n",
    "        # Create a client\n",
    "        cred = service_account.Credentials.from_service_account_file(\"secrets/docai_credentials.json\")\n",
    "        self.__client = documentai.DocumentProcessorServiceClient(\n",
    "            credentials=cred,\n",
    "            client_options={\"api_endpoint\": f\"{location}-documentai.googleapis.com\"}\n",
    "        )\n",
    "\n",
    "        # Get the processor\n",
    "        self.__processor = self.__client.processor_path(project=project_id, location=location, processor=processor_id)\n",
    "\n",
    "    # Method to extract the first year found in the document\n",
    "    def extract_year(self, original_text):\n",
    "        match = re.search(r\"\\b[^\\d]\\d{4}[^\\d]\\b\", original_text)\n",
    "        idx = match.span()[0]\n",
    "        end = match.span()[1]\n",
    "        \n",
    "        return original_text[idx:end].replace(\" \", \"\")\n",
    "    \n",
    "    # Method to create an indexed map of tokens\n",
    "    def get_map(self, doc, original_text):    \n",
    "        map = {}\n",
    "        for page in doc.pages:\n",
    "            for token in page.tokens:\n",
    "                idx = token.layout.text_anchor.text_segments[0].start_index\n",
    "                end = token.layout.text_anchor.text_segments[0].end_index\n",
    "                # The vertices go clockwise, starting on the upper left corner\n",
    "                vertices = [vertix for vertix in token.layout.bounding_poly.normalized_vertices]\n",
    "                map[idx] = (idx, end, original_text[idx:end], vertices)\n",
    "        \n",
    "        return map\n",
    "\n",
    "    def process_documents(self, department, municipality):\n",
    "\n",
    "        bucket_data = db.storage_get_images()\n",
    "\n",
    "        # Process each image\n",
    "        for uri, url in bucket_data:\n",
    "            # Get extension of images to set correct mime type\n",
    "            extension = uri[-3:]\n",
    "            if \"jpg\" in extension:\n",
    "                extension = \"jpeg\"\n",
    "            elif \"png\" in extension:\n",
    "                extension = \"png\"\n",
    "\n",
    "            # Create a raw document object\n",
    "            document = documentai.GcsDocument(gcs_uri=uri, mime_type=f\"image/{extension}\")\n",
    "\n",
    "             # Create API request\n",
    "            request = documentai.ProcessRequest(name=self.__processor, \n",
    "                                                gcs_document=document,\n",
    "                                                process_options={\"ocr_config\": {\n",
    "                                                    \"hints\": {\"language_hints\": \"es\"}\n",
    "                                                    }\n",
    "                                                })\n",
    "\n",
    "            # Get OCR result and text\n",
    "            ocr_result = self.__client.process_document(request=request).document\n",
    "            text = ocr_result.text\n",
    "\n",
    "            # Extract year from text\n",
    "            year = self.extract_year(text)\n",
    "\n",
    "            # Generate token map\n",
    "            token_map = self.get_map(ocr_result, text)\n",
    "\n",
    "            # Get blocks of text\n",
    "            block_idx = utils.get_indexes(ocr_result)\n",
    "\n",
    "            # Get processed blocks of text\n",
    "            text_blocks = []\n",
    "            for idx in block_idx:\n",
    "                text_block = utils.get_text(idx, text)\n",
    "                #print(f\"Block: {text_block}\")\n",
    "                text_blocks.append(utils.formatting(text_block))\n",
    "\n",
    "            # Extract names and bounding boxes from text blocks\n",
    "            ner = ner_model()\n",
    "            ner_results = ner.extract_names(text_blocks=text_blocks, original_text=text, token_map=token_map)\n",
    "\n",
    "            # Add document to Firestore Document collection\n",
    "            doc_id = db.create_document(year, department, municipality, url)\n",
    "\n",
    "            # Add a bounding box to Firestore Bounds collection\n",
    "            for ner_result in ner_results:\n",
    "                first_name = ner_result[\"first_name\"]\n",
    "                last_name = ner_result[\"last_name\"]\n",
    "                \n",
    "                if not first_name and not last_name:\n",
    "                    print(\"Skipping empty entry for: \", first_name, last_name)\n",
    "                else:\n",
    "                    # If first name or last name is None, set to empty string\n",
    "                    if not first_name:\n",
    "                        first_name = \"\"\n",
    "                    if not last_name:\n",
    "                        last_name = \"\"\n",
    "                        \n",
    "                    # Create a bounding box in the database\n",
    "                    db.create_bound(ner_result[\"bounding_box\"], doc_id, first_name, last_name)\n",
    "\n",
    "            # Print Success Message\n",
    "            print(\"Image processed successfully:\", url)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aaa77459",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/camilo/anaconda3/envs/genealogy-ocr/lib/python3.12/site-packages/spacy/util.py:910: UserWarning: [W095] Model 'es_core_news_lg' (3.7.0) was trained with spaCy v3.7.0 and may not be 100% compatible with the current version (3.8.2). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n",
      "/Users/camilo/anaconda3/envs/genealogy-ocr/lib/python3.12/site-packages/spacy/util.py:910: UserWarning: [W095] Model 'es_pipeline' (0.0.0) was trained with spaCy v3.7.2 and may not be 100% compatible with the current version (3.8.2). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- New Block ----------\n",
      "---------- New Block ----------\n",
      "## Name found by default model:  Guacamayas PER\n",
      "### Searching bounding box...\n",
      "#### Indexes:  106 117 String:  'Guacamayas.'\n",
      "#### No names found. Setting to none:  []\n",
      "#### No names found. Setting to none:  []\n",
      "---------- New Block ----------\n",
      "## Name found by default model:  Eleuterio PER\n",
      "### Searching bounding box...\n",
      "#### Indexes:  166 176 String:  'Eleuterio '\n",
      "     -- MATCHES MATCHER. Custom model results:  Eleuterio FIRST_NAME / Matcher results:  Eleuterio FIRST_NAME\n",
      "#### Joining first names...\n",
      "     -- First Names:  Eleuterio\n",
      "#### No names found. Setting to none:  []\n",
      "## Name found by default model:  Julian Patricio PER\n",
      "### Searching bounding box...\n",
      "#### Indexes:  178 196 String:  'Ju-\\nlian Patricio '\n",
      "     -- MATCHES MATCHER. Custom model results:  Julian FIRST_NAME / Matcher results:  Julian FIRST_NAME\n",
      "     -- MATCHES MATCHER. Custom model results:  Patricio FIRST_NAME / Matcher results:  Patricio FIRST_NAME\n",
      "#### Joining first names...\n",
      "     -- First Names:  Julian Patricio\n",
      "#### No names found. Setting to none:  []\n",
      "## Name found by default model:  Joaquín PER\n",
      "### Searching bounding box...\n",
      "#### Indexes:  205 213 String:  'Joaquín '\n",
      "     -- MATCHES MATCHER. Custom model results:  Joaquin FIRST_NAME / Matcher results:  Joaquin FIRST_NAME\n",
      "#### Joining first names...\n",
      "     -- First Names:  Joaquin\n",
      "#### No names found. Setting to none:  []\n",
      "## Name found by default model:  Alizal PER\n",
      "### Searching bounding box...\n",
      "#### Indexes:  297 304 String:  'Alizal,'\n",
      "#### No names found. Setting to none:  []\n",
      "#### No names found. Setting to none:  []\n",
      "## Name found by default model:  ycortade ra vereda do PER\n",
      "### Searching bounding box...\n",
      "#### Indexes:  305 327 String:  'ycortade\\nra vereda do.'\n",
      "     -- MATCHES MATCHER. Custom model results:  vereda LAST_NAME / Matcher results:  vereda LAST_NAME\n",
      "#### No names found. Setting to none:  []\n",
      "#### Joining last names...\n",
      "     -- Last Names:  vereda\n",
      "## Name found by default model:  laa Tapias PER\n",
      "### Searching bounding box...\n",
      "#### Indexes:  328 339 String:  'laa Tapias '\n",
      "     -- MATCHES MATCHER. Custom model results:  Tapias LAST_NAME / Matcher results:  Tapias LAST_NAME\n",
      "#### No names found. Setting to none:  []\n",
      "#### Joining last names...\n",
      "     -- Last Names:  Tapias\n",
      "## Name found by default model:  Juan Crisostomo Ro dríguez PER\n",
      "### Searching bounding box...\n",
      "#### Indexes:  493 520 String:  'Juan Crisostomo Ro\\ndríguez,'\n",
      "     -- MATCHES MATCHER. Custom model results:  Juan FIRST_NAME / Matcher results:  Juan FIRST_NAME\n",
      "     -- MATCHES MATCHER. Custom model results:  Crisostomo FIRST_NAME / Matcher results:  Crisostomo FIRST_NAME\n",
      "#### Joining first names...\n",
      "     -- First Names:  Juan Crisostomo\n",
      "#### No names found. Setting to none:  []\n",
      "---------- New Block ----------\n",
      "## Name found by default model:  Π PER\n",
      "### Searching bounding box...\n",
      "#### Indexes:  639 642 String:  'Π\\nJ'\n",
      "#### No names found. Setting to none:  []\n",
      "#### No names found. Setting to none:  []\n",
      "---------- New Block ----------\n",
      "## Name found by default model:  Javier Solano PER\n",
      "### Searching bounding box...\n",
      "#### Indexes:  641 655 String:  'Javier Solano '\n",
      "     -- MATCHES MATCHER. Custom model results:  Javier FIRST_NAME / Matcher results:  Javier FIRST_NAME\n",
      "     -- MATCHES MATCHER. Custom model results:  Solano LAST_NAME / Matcher results:  Solano LAST_NAME\n",
      "#### Joining first names...\n",
      "     -- First Names:  Javier\n",
      "#### Joining last names...\n",
      "     -- Last Names:  Solano\n",
      "## Name found by default model:  Gregorio Murillo PER\n",
      "### Searching bounding box...\n",
      "#### Indexes:  657 675 String:  'Gregorio Murillo\\no'\n",
      "     -- MATCHES MATCHER. Custom model results:  Gregorio FIRST_NAME / Matcher results:  Gregorio FIRST_NAME\n",
      "     -- MATCHES MATCHER. Custom model results:  Murillo FIRST_NAME / Matcher results:  Murillo FIRST_NAME\n",
      "#### Joining first names...\n",
      "     -- First Names:  Gregorio Murillo\n",
      "#### No names found. Setting to none:  []\n",
      "---------- New Block ----------\n",
      "---------- New Block ----------\n",
      "## Name found by default model:  Antonio José de Herrera PER\n",
      "### Searching bounding box...\n",
      "#### Indexes:  797 821 String:  'Antonio José de\\nHerrera '\n",
      "     -- MATCHES MATCHER. Custom model results:  Antonio FIRST_NAME / Matcher results:  Antonio FIRST_NAME\n",
      "     -- MATCHES MATCHER. Custom model results:  Jose FIRST_NAME / Matcher results:  Jose FIRST_NAME\n",
      "     -- MATCHES MATCHER. Custom model results:  Herrera LAST_NAME / Matcher results:  Herrera LAST_NAME\n",
      "#### Joining first names...\n",
      "     -- First Names:  Antonio Jose\n",
      "#### Joining last names...\n",
      "     -- Last Names:  Herrera\n",
      "## Name found by default model:  Mateo Marón PER\n",
      "### Searching bounding box...\n",
      "#### Indexes:  830 842 String:  'Mateo Marón '\n",
      "     -- MATCHES MATCHER. Custom model results:  Mateo FIRST_NAME / Matcher results:  Mateo FIRST_NAME\n",
      "     -- MATCHES MATCHER. Custom model results:  Maron LAST_NAME / Matcher results:  Maron LAST_NAME\n",
      "#### Joining first names...\n",
      "     -- First Names:  Mateo\n",
      "#### Joining last names...\n",
      "     -- Last Names:  Maron\n",
      "## Name found by default model:  Francisco Javier Leal PER\n",
      "### Searching bounding box...\n",
      "#### Indexes:  844 866 String:  'Francisco Javier Leal '\n",
      "     -- MATCHES MATCHER. Custom model results:  Francisco FIRST_NAME / Matcher results:  Francisco FIRST_NAME\n",
      "     -- MATCHES MATCHER. Custom model results:  Javier FIRST_NAME / Matcher results:  Javier FIRST_NAME\n",
      "     -- MATCHES MATCHER. Custom model results:  Leal LAST_NAME / Matcher results:  Leal LAST_NAME\n",
      "#### Joining first names...\n",
      "     -- First Names:  Francisco Javier\n",
      "#### Joining last names...\n",
      "     -- Last Names:  Leal\n",
      "---------- New Block ----------\n",
      "## Name found by default model:  Antonio José de Herrera PER\n",
      "### Searching bounding box...\n",
      "#### Indexes:  797 821 String:  'Antonio José de\\nHerrera '\n",
      "     -- MATCHES MATCHER. Custom model results:  Antonio FIRST_NAME / Matcher results:  Antonio FIRST_NAME\n",
      "     -- MATCHES MATCHER. Custom model results:  Jose FIRST_NAME / Matcher results:  Jose FIRST_NAME\n",
      "     -- MATCHES MATCHER. Custom model results:  Herrera LAST_NAME / Matcher results:  Herrera LAST_NAME\n",
      "#### Joining first names...\n",
      "     -- First Names:  Antonio Jose\n",
      "#### Joining last names...\n",
      "     -- Last Names:  Herrera\n",
      "## Name found by default model:  José Matero Burón PER\n",
      "### Searching bounding box...\n",
      "#### Indexes:  1037 1055 String:  'José Matero Burón '\n",
      "     -- MATCHES MATCHER. Custom model results:  Jose FIRST_NAME / Matcher results:  Jose FIRST_NAME\n",
      "     -- MATCHES MATCHER. Custom model results:  Buron LAST_NAME / Matcher results:  Buron LAST_NAME\n",
      "#### Joining first names...\n",
      "     -- First Names:  Jose\n",
      "#### Joining last names...\n",
      "     -- Last Names:  Buron\n",
      "## Name found by default model:  Francisco Javier Leal PER\n",
      "### Searching bounding box...\n",
      "#### Indexes:  844 866 String:  'Francisco Javier Leal '\n",
      "     -- MATCHES MATCHER. Custom model results:  Francisco FIRST_NAME / Matcher results:  Francisco FIRST_NAME\n",
      "     -- MATCHES MATCHER. Custom model results:  Javier FIRST_NAME / Matcher results:  Javier FIRST_NAME\n",
      "     -- MATCHES MATCHER. Custom model results:  Leal LAST_NAME / Matcher results:  Leal LAST_NAME\n",
      "#### Joining first names...\n",
      "     -- First Names:  Francisco Javier\n",
      "#### Joining last names...\n",
      "     -- Last Names:  Leal\n",
      "## Name found by default model:  Antonio de Herre za Lovatón PER\n",
      "### Searching bounding box...\n",
      "#### Indexes:  1200 1228 String:  'Antonio de Herre\\nza Lovatón '\n",
      "     -- MATCHES MATCHER. Custom model results:  Antonio FIRST_NAME / Matcher results:  Antonio FIRST_NAME\n",
      "#### Joining first names...\n",
      "     -- First Names:  Antonio\n",
      "#### No names found. Setting to none:  []\n",
      "---------- New Block ----------\n",
      "## Name found by default model:  Juan Toure PER\n",
      "### Searching bounding box...\n",
      "#### Indexes:  1371 1382 String:  'Juan Toure,'\n",
      "     -- MATCHES MATCHER. Custom model results:  Juan FIRST_NAME / Matcher results:  Juan FIRST_NAME\n",
      "     -- MATCHES MATCHER. Custom model results:  Toure FIRST_NAME / Matcher results:  Toure FIRST_NAME\n",
      "#### Joining first names...\n",
      "     -- First Names:  Juan Toure\n",
      "#### No names found. Setting to none:  []\n",
      "## Name found by default model:  Mi guel Chacón PER\n",
      "### Searching bounding box...\n",
      "#### Indexes:  1384 1399 String:  'Mi\\nguel Chacón '\n",
      "     -- MATCHES MATCHER. Custom model results:  Mi FIRST_NAME / Matcher results:  Mi FIRST_NAME\n",
      "     -- MATCHES MATCHER. Custom model results:  Chacon LAST_NAME / Matcher results:  Chacon LAST_NAME\n",
      "#### Joining first names...\n",
      "     -- First Names:  Mi Miguel\n",
      "#### Joining last names...\n",
      "     -- Last Names:  Chacon\n",
      "## Name found by default model:  Cruz Barrera PER\n",
      "### Searching bounding box...\n",
      "#### Indexes:  1408 1421 String:  'Cruz Barrera,'\n",
      "     -- MATCHES MATCHER. Custom model results:  Cruz FIRST_NAME / Matcher results:  Cruz FIRST_NAME\n",
      "     -- MATCHES MATCHER. Custom model results:  Barrera LAST_NAME / Matcher results:  Barrera LAST_NAME\n",
      "#### Joining first names...\n",
      "     -- First Names:  Cruz\n",
      "#### Joining last names...\n",
      "     -- Last Names:  Barrera\n",
      "## Name found by default model:  Chacón PER\n",
      "### Searching bounding box...\n",
      "#### Indexes:  1392 1399 String:  'Chacón '\n",
      "     -- MATCHES MATCHER. Custom model results:  Chacon LAST_NAME / Matcher results:  Chacon LAST_NAME\n",
      "#### No names found. Setting to none:  []\n",
      "#### Joining last names...\n",
      "     -- Last Names:  Chacon\n",
      "## Name found by default model:  hubier PER\n",
      "### Searching bounding box...\n",
      "#### Indexes:  1511 1519 String:  'hubier\\nr'\n",
      "#### No names found. Setting to none:  []\n",
      "#### No names found. Setting to none:  []\n",
      "## Name found by default model:  Domingo Cuchavara PER\n",
      "### Searching bounding box...\n",
      "#### Indexes:  1535 1554 String:  'Domingo Cuchavara\\n3'\n",
      "     -- MATCHES MATCHER. Custom model results:  Domingo FIRST_NAME / Matcher results:  Domingo FIRST_NAME\n",
      "#### Joining first names...\n",
      "     -- First Names:  Domingo\n",
      "#### No names found. Setting to none:  []\n",
      "---------- New Block ----------\n",
      "## Name found by default model:  Barrera PER\n",
      "### Searching bounding box...\n",
      "#### Indexes:  1413 1421 String:  'Barrera,'\n",
      "     -- MATCHES MATCHER. Custom model results:  Barrera LAST_NAME / Matcher results:  Barrera LAST_NAME\n",
      "#### No names found. Setting to none:  []\n",
      "#### Joining last names...\n",
      "     -- Last Names:  Barrera\n",
      "## Name found by default model:  Jesús Patiño PER\n",
      "### Searching bounding box...\n",
      "#### Indexes:  1622 1635 String:  'Jesús Patiño,'\n",
      "     -- MATCHES MATCHER. Custom model results:  Jesus FIRST_NAME / Matcher results:  Jesus FIRST_NAME\n",
      "     -- MATCHES MATCHER. Custom model results:  Patiño LAST_NAME / Matcher results:  Patiño LAST_NAME\n",
      "#### Joining first names...\n",
      "     -- First Names:  Jesus\n",
      "#### Joining last names...\n",
      "     -- Last Names:  Patiño\n",
      "## Name found by default model:  Je sús Támara PER\n",
      "### Searching bounding box...\n",
      "#### Indexes:  1743 1757 String:  'Je\\nsús Támara,'\n",
      "     -- MATCHES MATCHER. Custom model results:  sus LAST_NAME / Matcher results:  sus LAST_NAME\n",
      "     -- MATCHES MATCHER. Custom model results:  Tamara FIRST_NAME / Matcher results:  Tamara FIRST_NAME\n",
      "#### Joining first names...\n",
      "     -- First Names:  Tamara\n",
      "#### Joining last names...\n",
      "     -- Last Names:  sus\n",
      "## Name found by default model:  Miguel Chacón PER\n",
      "### Searching bounding box...\n",
      "#### Indexes:  1384 1399 String:  'Mi\\nguel Chacón '\n",
      "     -- MATCHES MATCHER. Custom model results:  Miguel FIRST_NAME / Matcher results:  Miguel FIRST_NAME\n",
      "     -- MATCHES MATCHER. Custom model results:  Chacon LAST_NAME / Matcher results:  Chacon LAST_NAME\n",
      "#### Joining first names...\n",
      "     -- First Names:  Miguel\n",
      "#### Joining last names...\n",
      "     -- Last Names:  Chacon\n",
      "## Name found by default model:  1858--Camila Muñoz PER\n",
      "### Searching bounding box...\n",
      "#### Indexes:  1817 1836 String:  '1858--Camila Muñoz,'\n",
      "     -- MATCHES MATCHER. Custom model results:  Muñoz LAST_NAME / Matcher results:  Muñoz LAST_NAME\n",
      "#### No names found. Setting to none:  []\n",
      "#### Joining last names...\n",
      "     -- Last Names:  Muñoz\n",
      "## Name found by default model:  Antonio Herrera PER\n",
      "### Searching bounding box...\n",
      "#### Indexes:  1847 1863 String:  'Antonio Herrera '\n",
      "     -- MATCHES MATCHER. Custom model results:  Antonio FIRST_NAME / Matcher results:  Antonio FIRST_NAME\n",
      "     -- MATCHES MATCHER. Custom model results:  Herrera LAST_NAME / Matcher results:  Herrera LAST_NAME\n",
      "#### Joining first names...\n",
      "     -- First Names:  Antonio\n",
      "#### Joining last names...\n",
      "     -- Last Names:  Herrera\n",
      "---------- New Block ----------\n",
      "---------- New Block ----------\n",
      "---------- New Block ----------\n",
      "Document added. ID:  DzkzCnBYrLEURjopnLdU\n",
      "Skipping empty entry for:  None None\n",
      "Bounds added. Data added: \n",
      "{'bounds': [{'x': 0.8495420813560486, 'y': 0.13516895473003387}, {'x': 0.8953336477279663, 'y': 0.13516895473003387}, {'x': 0.8953336477279663, 'y': 0.1464330404996872}, {'x': 0.8495420813560486, 'y': 0.1464330404996872}], 'doc_id': 'DzkzCnBYrLEURjopnLdU', 'first_name': 'Eleuterio', 'last_name': ''}\n",
      "ID:  nEmcHl3A84e2yqdYTi5Z\n",
      "Bounds added. Data added: \n",
      "{'bounds': [{'x': 0.9105974435806274, 'y': 0.13516895473003387}, {'x': 0.6655036807060242, 'y': 0.15894868969917297}, {'x': 0.6655036807060242, 'y': 0.168335422873497}, {'x': 0.9105974435806274, 'y': 0.1464330404996872}], 'doc_id': 'DzkzCnBYrLEURjopnLdU', 'first_name': 'Julian Patricio', 'last_name': ''}\n",
      "ID:  mMpMhwhK7iSofPlwbDPA\n",
      "Bounds added. Data added: \n",
      "{'bounds': [{'x': 0.7226340770721436, 'y': 0.1595744639635086}, {'x': 0.7583951354026794, 'y': 0.1595744639635086}, {'x': 0.7583951354026794, 'y': 0.17083854973316193}, {'x': 0.7226340770721436, 'y': 0.17083854973316193}], 'doc_id': 'DzkzCnBYrLEURjopnLdU', 'first_name': 'Joaquin', 'last_name': ''}\n",
      "ID:  gGudpO0Muove6gxalcnT\n",
      "Skipping empty entry for:  None None\n",
      "Bounds added. Data added: \n",
      "{'bounds': [{'x': 0.889228105545044, 'y': 0.1833541989326477}, {'x': 0.6637592911720276, 'y': 0.20650812983512878}, {'x': 0.6637592911720276, 'y': 0.21839800477027893}, {'x': 0.889228105545044, 'y': 0.1958698332309723}], 'doc_id': 'DzkzCnBYrLEURjopnLdU', 'first_name': '', 'last_name': 'vereda'}\n",
      "ID:  bAeYfEDyYuogMFcuuxGd\n",
      "Bounds added. Data added: \n",
      "{'bounds': [{'x': 0.6659398078918457, 'y': 0.20650812983512878}, {'x': 0.7169646620750427, 'y': 0.20650812983512878}, {'x': 0.7169646620750427, 'y': 0.21839800477027893}, {'x': 0.6659398078918457, 'y': 0.21839800477027893}], 'doc_id': 'DzkzCnBYrLEURjopnLdU', 'first_name': '', 'last_name': 'Tapias'}\n",
      "ID:  LjqKTMcFSsqX9G9VgMFL\n",
      "Bounds added. Data added: \n",
      "{'bounds': [{'x': 0.8334060311317444, 'y': 0.26658323407173157}, {'x': 0.6389009952545166, 'y': 0.2916145324707031}, {'x': 0.6389009952545166, 'y': 0.3041301667690277}, {'x': 0.8334060311317444, 'y': 0.279724657535553}], 'doc_id': 'DzkzCnBYrLEURjopnLdU', 'first_name': 'Juan Crisostomo', 'last_name': ''}\n",
      "ID:  JF17Sazp5kW3mTUIlq35\n",
      "Skipping empty entry for:  None None\n",
      "Bounds added. Data added: \n",
      "{'bounds': [{'x': 0.5996510982513428, 'y': 0.3404255211353302}, {'x': 0.6641953587532043, 'y': 0.3404255211353302}, {'x': 0.6641953587532043, 'y': 0.3516896069049835}, {'x': 0.5996510982513428, 'y': 0.3516896069049835}], 'doc_id': 'DzkzCnBYrLEURjopnLdU', 'first_name': 'Javier', 'last_name': 'Solano'}\n",
      "ID:  mHwVIMUtmTi3df0zaUyE\n",
      "Bounds added. Data added: \n",
      "{'bounds': [{'x': 0.6794592142105103, 'y': 0.3404255211353302}, {'x': 0.20366331934928894, 'y': 0.953066349029541}, {'x': 0.20366331934928894, 'y': 0.9612014889717102}, {'x': 0.6794592142105103, 'y': 0.3516896069049835}], 'doc_id': 'DzkzCnBYrLEURjopnLdU', 'first_name': 'Gregorio Murillo', 'last_name': ''}\n",
      "ID:  sFjHj09vRAYlGCRnoV4N\n",
      "Bounds added. Data added: \n",
      "{'bounds': [{'x': 0.8456171154975891, 'y': 0.40175220370292664}, {'x': 0.6332315802574158, 'y': 0.42553192377090454}, {'x': 0.6332315802574158, 'y': 0.43679600954055786}, {'x': 0.8456171154975891, 'y': 0.4142678380012512}], 'doc_id': 'DzkzCnBYrLEURjopnLdU', 'first_name': 'Antonio Jose', 'last_name': 'Herrera'}\n",
      "ID:  iFsIZzdBzoLlopyNuD0x\n",
      "Bounds added. Data added: \n",
      "{'bounds': [{'x': 0.6881814002990723, 'y': 0.42553192377090454}, {'x': 0.7457479238510132, 'y': 0.42553192377090454}, {'x': 0.7457479238510132, 'y': 0.43679600954055786}, {'x': 0.6881814002990723, 'y': 0.43679600954055786}], 'doc_id': 'DzkzCnBYrLEURjopnLdU', 'first_name': 'Mateo', 'last_name': 'Maron'}\n",
      "ID:  4JJHRTzyvLepAzz6ThK3\n",
      "Bounds added. Data added: \n",
      "{'bounds': [{'x': 0.7601395845413208, 'y': 0.42553192377090454}, {'x': 0.8669864535331726, 'y': 0.42553192377090454}, {'x': 0.8669864535331726, 'y': 0.43679600954055786}, {'x': 0.7601395845413208, 'y': 0.43679600954055786}], 'doc_id': 'DzkzCnBYrLEURjopnLdU', 'first_name': 'Francisco Javier', 'last_name': 'Leal'}\n",
      "ID:  IPvnmyR0HIeB6wKAyUrq\n",
      "Bounds added. Data added: \n",
      "{'bounds': [{'x': 0.8456171154975891, 'y': 0.40175220370292664}, {'x': 0.6332315802574158, 'y': 0.42553192377090454}, {'x': 0.6332315802574158, 'y': 0.43679600954055786}, {'x': 0.8456171154975891, 'y': 0.4142678380012512}], 'doc_id': 'DzkzCnBYrLEURjopnLdU', 'first_name': 'Antonio Jose', 'last_name': 'Herrera'}\n",
      "ID:  26KlXbPRLVhK51RdDLaG\n",
      "Bounds added. Data added: \n",
      "{'bounds': [{'x': 0.6934147477149963, 'y': 0.5325406789779663}, {'x': 0.7802006006240845, 'y': 0.5331664681434631}, {'x': 0.7802006006240845, 'y': 0.5456821322441101}, {'x': 0.6934147477149963, 'y': 0.5450563430786133}], 'doc_id': 'DzkzCnBYrLEURjopnLdU', 'first_name': 'Jose', 'last_name': 'Buron'}\n",
      "ID:  IIhC525n0W8AWTieKsES\n",
      "Bounds added. Data added: \n",
      "{'bounds': [{'x': 0.7601395845413208, 'y': 0.42553192377090454}, {'x': 0.8669864535331726, 'y': 0.42553192377090454}, {'x': 0.8669864535331726, 'y': 0.43679600954055786}, {'x': 0.7601395845413208, 'y': 0.43679600954055786}], 'doc_id': 'DzkzCnBYrLEURjopnLdU', 'first_name': 'Francisco Javier', 'last_name': 'Leal'}\n",
      "ID:  Xafzg8Bvmg7dJAunBn6H\n",
      "Bounds added. Data added: \n",
      "{'bounds': [{'x': 0.849105954170227, 'y': 0.5838547945022583}, {'x': 0.6471871137619019, 'y': 0.6051313877105713}, {'x': 0.6471871137619019, 'y': 0.6188986301422119}, {'x': 0.849105954170227, 'y': 0.5963704586029053}], 'doc_id': 'DzkzCnBYrLEURjopnLdU', 'first_name': 'Antonio', 'last_name': ''}\n",
      "ID:  TJYGAPsHl0zcNEnYQ8FI\n",
      "Bounds added. Data added: \n",
      "{'bounds': [{'x': 0.8443087935447693, 'y': 0.6683354377746582}, {'x': 0.9036197066307068, 'y': 0.668961226940155}, {'x': 0.9036197066307068, 'y': 0.6827284097671509}, {'x': 0.8443087935447693, 'y': 0.682102620601654}], 'doc_id': 'DzkzCnBYrLEURjopnLdU', 'first_name': 'Juan Toure', 'last_name': ''}\n",
      "ID:  QcPAL6CI42hrg9IrEoEH\n",
      "Bounds added. Data added: \n",
      "{'bounds': [{'x': 0.9136502146720886, 'y': 0.668961226940155}, {'x': 0.6511120796203613, 'y': 0.6914893388748169}, {'x': 0.6511120796203613, 'y': 0.703379213809967}, {'x': 0.9136502146720886, 'y': 0.6827284097671509}], 'doc_id': 'DzkzCnBYrLEURjopnLdU', 'first_name': 'Mi Miguel', 'last_name': 'Chacon'}\n",
      "ID:  k7zKscUn0qWwpLfZUrRT\n",
      "Bounds added. Data added: \n",
      "{'bounds': [{'x': 0.7012647390365601, 'y': 0.6921151280403137}, {'x': 0.7723506093025208, 'y': 0.6927409172058105}, {'x': 0.7723506093025208, 'y': 0.7046307921409607}, {'x': 0.7012647390365601, 'y': 0.7040050029754639}], 'doc_id': 'DzkzCnBYrLEURjopnLdU', 'first_name': 'Cruz', 'last_name': 'Barrera'}\n",
      "ID:  7bdtQB194J0fFfMehior\n",
      "Bounds added. Data added: \n",
      "{'bounds': [{'x': 0.6192760467529297, 'y': 0.6908635497093201}, {'x': 0.6511120796203613, 'y': 0.6914893388748169}, {'x': 0.6511120796203613, 'y': 0.703379213809967}, {'x': 0.6192760467529297, 'y': 0.7027534246444702}], 'doc_id': 'DzkzCnBYrLEURjopnLdU', 'first_name': '', 'last_name': 'Chacon'}\n",
      "ID:  sk6dcWNBBMx6Ma55Dhcz\n",
      "Skipping empty entry for:  None None\n",
      "Bounds added. Data added: \n",
      "{'bounds': [{'x': 0.6798953413963318, 'y': 0.7409261465072632}, {'x': 0.6096816658973694, 'y': 0.7740926146507263}, {'x': 0.6096816658973694, 'y': 0.7872340679168701}, {'x': 0.6798953413963318, 'y': 0.7515644431114197}], 'doc_id': 'DzkzCnBYrLEURjopnLdU', 'first_name': 'Domingo', 'last_name': ''}\n",
      "ID:  iRFkcDd3ncv4w2CHoajI\n",
      "Bounds added. Data added: \n",
      "{'bounds': [{'x': 0.7261229753494263, 'y': 0.6921151280403137}, {'x': 0.7723506093025208, 'y': 0.6927409172058105}, {'x': 0.7723506093025208, 'y': 0.7046307921409607}, {'x': 0.7261229753494263, 'y': 0.7046307921409607}], 'doc_id': 'DzkzCnBYrLEURjopnLdU', 'first_name': '', 'last_name': 'Barrera'}\n",
      "ID:  n5z0zdwrGGVmsjF72quz\n",
      "Bounds added. Data added: \n",
      "{'bounds': [{'x': 0.6345399022102356, 'y': 0.7997496724128723}, {'x': 0.6990841627120972, 'y': 0.801001250743866}, {'x': 0.6990841627120972, 'y': 0.8122653365135193}, {'x': 0.6345399022102356, 'y': 0.8116395473480225}], 'doc_id': 'DzkzCnBYrLEURjopnLdU', 'first_name': 'Jesus', 'last_name': 'Patiño'}\n",
      "ID:  8DHbkIxcy7FcuCEl4azg\n",
      "Bounds added. Data added: \n",
      "{'bounds': [{'x': 0.9127780199050903, 'y': 0.8297872543334961}, {'x': 0.6476231813430786, 'y': 0.847934901714325}, {'x': 0.6476231813430786, 'y': 0.8610763549804688}, {'x': 0.9127780199050903, 'y': 0.8372966051101685}], 'doc_id': 'DzkzCnBYrLEURjopnLdU', 'first_name': 'Tamara', 'last_name': 'sus'}\n",
      "ID:  qsozQr0zYR2np5p9RwOB\n",
      "Bounds added. Data added: \n",
      "{'bounds': [{'x': 0.9136502146720886, 'y': 0.668961226940155}, {'x': 0.6511120796203613, 'y': 0.6914893388748169}, {'x': 0.6511120796203613, 'y': 0.703379213809967}, {'x': 0.9136502146720886, 'y': 0.6827284097671509}], 'doc_id': 'DzkzCnBYrLEURjopnLdU', 'first_name': 'Miguel', 'last_name': 'Chacon'}\n",
      "ID:  o1DOoyCMLH31PGELiB0t\n",
      "Bounds added. Data added: \n",
      "{'bounds': [{'x': 0.8163977265357971, 'y': 0.8867334127426147}, {'x': 0.9123418927192688, 'y': 0.8886107802391052}, {'x': 0.9123418927192688, 'y': 0.9017521739006042}, {'x': 0.8163977265357971, 'y': 0.9005006551742554}], 'doc_id': 'DzkzCnBYrLEURjopnLdU', 'first_name': '', 'last_name': 'Muñoz'}\n",
      "ID:  4sEymLMW6x4UeS9brSA3\n",
      "Bounds added. Data added: \n",
      "{'bounds': [{'x': 0.6327954530715942, 'y': 0.9117646813392639}, {'x': 0.709114670753479, 'y': 0.9155194163322449}, {'x': 0.7086786031723022, 'y': 0.9255319237709045}, {'x': 0.6323593258857727, 'y': 0.9211514592170715}], 'doc_id': 'DzkzCnBYrLEURjopnLdU', 'first_name': 'Antonio', 'last_name': 'Herrera'}\n",
      "ID:  mYKBvsMDFXXOELolZV5I\n",
      "Image processed successfully: https://firebasestorage.googleapis.com/v0/b/genealogy-index.firebasestorage.app/o/test_images%2Ftest_image_typewriter.jpg?alt=media&token=2c3ee7b7-7741-4dd4-8d4f-19bb009de4b2\n"
     ]
    }
   ],
   "source": [
    "# Send API call and process documents\n",
    "engine = ocr_engine()\n",
    "result = engine.process_documents(\"Cundinamarca\",\"Gachetá\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genealogy-ocr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
